{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIBLIOTECA DE FUNCIONES <a class=\"anchor\" id=\"0-0\"></a>\n",
    "\n",
    "    Este notebook es un documento auxiliar que sirve de repositorio para describir y/o consultar las funciones que se van creando a lo largo del proyecto. \n",
    "\n",
    "1. [Función: Genera EDA](#1)\n",
    "\n",
    "2. [Función: Convierte un archivo PKL a JSON](#2)\n",
    "\n",
    "3. [Función: Convierte PKL a DF](#3)\n",
    "\n",
    "4. [Función: Convierte consulta Mongo DB a DF](#4)\n",
    "\n",
    "5. [Función: Convierte de milisegundos a fecha larga](#5)\n",
    "\n",
    "6. [Función: Convierte JSON a DF](#6)\n",
    "\n",
    "7. [Función: Convierte milisegundos a fecha corta](#7)\n",
    "\n",
    "8. [Función: Crea ID](#8)\n",
    "\n",
    "9. [Función: Tokeniza texto](#9)\n",
    "\n",
    "10. [Función: Analiza columna](#10)\n",
    "\n",
    "11. [Función: Crea respaldo de la base de datos (dump)](#11)\n",
    "\n",
    "12. [Función: Inyecta registros en Mongo por lotes](#12)\n",
    "\n",
    "13. [Función: Limpia una base de datos (delete)](#13)\n",
    "\n",
    "14. [Función: Lee JSON a DF e inyecta DF a JSON](#14)\n",
    "\n",
    "15. [Función: Crea colecciones en BBDD Mongo DB](#15)\n",
    "\n",
    "16. [Función: Crea colecciones en BBDD Mongo DB (2)](#16)\n",
    "\n",
    "17. [Función: Mostrar tablas en SQLite](#17)\n",
    "\n",
    "18. [Procedimiento: Genera imágenes WORDCLOUD (Alt 1)](#18)\n",
    "\n",
    "19. [Procedimiento: Genera imágenes WORDCLOUD (Alt 2)](#19)\n",
    "\n",
    "20. [Función: Convierte consulta a Mongo en un df (Google, Paso 1 de 3)](#20)\n",
    "\n",
    "21. [Función: Función: Divide dirección (Google, paso 2 de 3)](#21)\n",
    "\n",
    "22. [Función: Divide ZIP (Google,paso 3 de 3)](#22)\n",
    "\n",
    "23. [Función: Convierte datos de categorías a un diccionario](#23)\n",
    "\n",
    "24. [Función: Agrega Estado](#24)\n",
    "\n",
    "25. [Función: Elimina datos de colección Mongo DB](#25)\n",
    "\n",
    "26. [Función: Analiza faltantes](#26)\n",
    "\n",
    "27. [Función: Rango de fechas](#27)\n",
    "\n",
    "28. [Función: ](#28)\n",
    "\n",
    "29. [Función: ](#29)\n",
    "\n",
    "30. [Función: ](#30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Función: Genera EDA<a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "    Útil si el df es tabular, no está pensado para datos anidados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que permite generar un informe tipo EDA del dataframe.\n",
    "# **************************************************************\n",
    "# Esta función se usará para el diagnóstico inicial y final de los datos.\n",
    "# Genera información valiosa para conocer el estadoy consistencia de los datos. \n",
    "#\n",
    "def f_reportedf(dataframe, nombre):\n",
    "    \"\"\"\n",
    "    Función que permite generar un informe tipo EDA del dataframe.\n",
    "    Recibe como parámetros, un dataframe y una cadena de texto \n",
    "    que describe el set de datos. \n",
    "    Retorna:\n",
    "    \n",
    "        a) Nombre del DF, número de registros y columnas\n",
    "        \n",
    "        b) Si el dataset tiene duplicados y cuántos.\n",
    "        \n",
    "        b) 2 registros de muestra, tomados al azar.\n",
    "        \n",
    "        c) Nombres de las columnas\n",
    "        \n",
    "        d) Estadísticas básicas de las columnas numéricas\n",
    "        \n",
    "        e) Valores únicos por cada columna\n",
    "        \n",
    "        f) Porcentaje de nulos por cada columna\n",
    "        \n",
    "        g) Estadísticas básicas de las columnas categóricas\n",
    "        \n",
    "        h) Tabla descriptiva del set de datos\n",
    "    \"\"\"\n",
    "    print(f\"RESUMEN ANÁLISIS EXPLORATORIO DE DATOS: {nombre.upper()}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"El DF tiene {dataframe.shape[0]} registros y {dataframe.shape[1]} columnas\")\n",
    "    print(\"-\"*50)\n",
    "    if dataframe.duplicated().sum() == 0: \n",
    "        print('El dataset no tiene duplicados')\n",
    "    else:\n",
    "        print(f\"El DF tiene {dataframe.duplicated().sum()} registros duplicados\") \n",
    "    print(\"-\"*50)\n",
    "    print(\"Para chequear estructura y tipos de datos, se muestran dos (2) filas seleccionadas al azar:\")\n",
    "    display(dataframe.sample(2).style.background_gradient(cmap='Oranges_r').set_properties(**{'font-family': 'Segoe UI'}).hide_index())\n",
    "    print(\"-\"*50)\n",
    "    print(f\"El dataframe {nombre} tiene las siguientes columnas y tipos de datos:\")\n",
    "    for i, col in enumerate(dataframe.columns, start=1):\n",
    "        print(i,') ',col, type(dataframe[col].iloc[0]))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Las estadísticas básicas de las variables numéricas son:\")\n",
    "    display(dataframe.select_dtypes(exclude='object').describe().T.style.background_gradient(cmap='Oranges_r').set_properties(**{'font-family': 'Segoe UI'}))\n",
    "    print(\"-\"*50)\n",
    "    print(\"El numero de valores distintos de cada columna es:\")\n",
    "    for col in dataframe.columns:\n",
    "        if len(dataframe[col].value_counts()) > 15:\n",
    "            print(col, len(dataframe[col].value_counts()))\n",
    "        else:\n",
    "            print(col, len(dataframe[col].value_counts()))\n",
    "            print(f\"Los valores son: {dataframe[col].unique()}\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"El porcentaje de nulos por columna:\")\n",
    "    for i, col in enumerate(dataframe.isnull().sum()):\n",
    "        print(f\"{dataframe.isnull().sum().index[i]}: {col/dataframe.shape[0]*100}\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"Las estadísticas básicas de las variables categóricas son:\")\n",
    "    try:\n",
    "        if dataframe.select_dtypes(include='object').shape[1] > 0:\n",
    "            display(dataframe.select_dtypes(include='object').describe().T.style.background_gradient(cmap='Oranges_r').set_properties(**{'font-family': 'Segoe UI'}))\n",
    "        else:\n",
    "            print(\"No se encontraron variables categóricas en el dataframe.\")\n",
    "    except AttributeError:\n",
    "        print(\"No se encontraron variables categóricas en el dataframe.\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"Tabla descriptiva que incluye todas las variables:\")\n",
    "    display(dataframe.describe(include='all').style \\\n",
    "  .format(precision=2, thousands=\",\", decimal=\".\").background_gradient(cmap='Oranges_r').set_properties(**{'font-family': 'Segoe UI'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Función: Convierte un archivo PKL a JSON<a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "    Necesario para convertir uno de los archivos del set de datos originales.\n",
    "\n",
    "    Recibe una ruta, que lleva a archivo .pkl, y retorna un archivo en formato json en el mismo directorio de origen u otra ruta que se especifique. \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Función: Convierte de PKL a JSON (f_pkl2json())\n",
    "# ***********************************************\n",
    "#\n",
    "def f_pkl2json(v_entra, v_sale):\n",
    "    \"\"\"\n",
    "    Recibe un archivo en formato PKL \n",
    "    y lo convierte a formato JSON\n",
    "    \"\"\"\n",
    "    # Dentro de un ciclo try/except para manejar excepciones\n",
    "    try:\n",
    "        # Lee el .pkl\n",
    "        with open(v_entra, 'rb') as v_file:\n",
    "            data = pickle.load(v_file)\n",
    "\n",
    "        # Convierte a JSON\n",
    "        with open(v_sale, 'w') as v_jsonFile:\n",
    "            json.dump(data, v_jsonFile, indent=4)\n",
    "\n",
    "        print(f\"Conversión finalizada. El archivo JSON se ha guardado en: {v_sale}\") # Se guarda enel directorio activo o ruta especificada\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir el archivo: {e}\") # Muestra el error, en caso de falla\n",
    "\n",
    "# Ejecución\n",
    "# *********\n",
    "#\n",
    "v_entra = 'D://business.pkl'         # Reemplazar 'nom_archivo.pkl' y la ruta\n",
    "v_sale  = 'D://test040823_biz.json'  # Reemplazar 'nom_archivo.json' con el nombre del archivo destino\n",
    "f_pkl2json(v_entra, v_sale)          # Obs: verificar que el pkl sea serializable (que no sea, por ejemplo, un modelo de ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Función: Convierte PKL a DF<a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "Lee archivo local, en formato PKL, y lo convierte a DF\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Función: Convierte de PKL a DF (f_pkl2df())\n",
    "# ***********************************************\n",
    "# \n",
    "def f_pkl2df(v_pkl):\n",
    "    \"\"\"\n",
    "    Recibe un archivo en formato PKL\n",
    "    lo covierte a dataframe de Pandas. \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Lee el .pkl y lo convierte en un df\n",
    "        df = pd.read_pickle(v_pkl)\n",
    "\n",
    "        print(\"Conversión terminada, 1 df ha sido creado.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir el archivo: {e}\")\n",
    "        return None\n",
    "\n",
    "# Ejecución\n",
    "# *********\n",
    "#\n",
    "v_pkl = 'D://business.pkl'       # Reemplazar 'nom_archivo.pkl' y la ruta\n",
    "\n",
    "df_ybusiness = f_pkl2df(v_pkl)\n",
    "if df_ybusiness is not None:\n",
    "    print(df_ybusiness.head(3))  # Muestrea 3 registros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Función: Convierte consulta Mongo DB a DF<a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "    Convierte una consulta a la BBDD, recibe como parámetros nombre de la BBDD y colección  \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Función: Convierte consulta en Mongo DB a dataframe\n",
    "# ***************************************************\n",
    "#\n",
    "\n",
    "def f_deMongoaDF(v_nomDB, v_nomCollection):\n",
    "    '''\n",
    "    Función que hace una consulta en Mongo DB\n",
    "    Recibe  : El nombre de una BBDD y una colección\n",
    "    Retorna : Un df \n",
    "    '''\n",
    "    \n",
    "    # String de conexión\n",
    "    client     = MongoClient('localhost', 27017)\n",
    "    db         = client[v_nomDB]\n",
    "    collection = db[v_nomCollection]\n",
    "\n",
    "    # Pipe para consulta a la colección\n",
    "    query = collection.find({}, {\n",
    "        'business_id' : 1,  # El valor 0 indica no se incluye y 1 si se incluye\n",
    "        'name'        : 1,\n",
    "        'address'     : 1,\n",
    "        'postal_code' : 1,\n",
    "        '_id'         : 0   # Índice interno de Mongo DB, por eso se excluye\n",
    "    })\n",
    "\n",
    "    # Con el resultado de la consulta, crea un DF\n",
    "    df_ybiz = pd.DataFrame(query)       # 'df_' por 'dataframe', 'y' por 'Yelp', y 'biz' por 'business'\n",
    "\n",
    "    # Cerrar la conexión con la base de datos\n",
    "    client.close()\n",
    "\n",
    "    return df_ybiz\n",
    "\n",
    "# Ejecución\n",
    "# *********\n",
    "#\n",
    "df_ybiz = f_deMongoaDF('yelpdb', 'business')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Función: Convierte de milisegundos a fecha larga<a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "    Función usada para convertir el campo time de la tabla de rviews en la bbdd Google Maps.\n",
    "\n",
    "    Args    : Un valor en milisegundos\n",
    "    Retorna : Una fcha en formato largo\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha convertida: 2020-08-11 13:51:12.670000\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# Función: Convierte fecha\n",
    "# ************************\n",
    "# Recibe  : Un entero de la forma \"1597168272670\"\n",
    "# Retorna : Una fecha de la forma \"Fecha convertida: 2020-08-11 13:51:12.670000\"\n",
    "# Nota: Para correr proceso masivo se debe eliminar el mensaje y sólo\n",
    "# retornar el valor. Se usa en combinación con una función lambda\n",
    "# para recorrer una variable o dentro de otras funciones.\n",
    "# Usar en las reviews de GOOGLE\n",
    "\n",
    "def f_convierteFecms(v_claveval):\n",
    "    # Como el set de datos no es claro, se verifica si el valor \n",
    "    # es en milisegundos o segundos y se ajusta si es necesario\n",
    "    if v_claveval > 9999999999:   # Si el valor es mayor a 10 dígitos, \n",
    "        v_claveval /= 1000        # se asume que está en milisegundos\n",
    "\n",
    "    return datetime.datetime.fromtimestamp(v_claveval)\n",
    "\n",
    "# Testeo\n",
    "# ******\n",
    "#\n",
    "v_dataEjemplo   = 1597168272670\n",
    "v_fecConvertida = f_convierteFecms(v_dataEjemplo)\n",
    "print(\"Fecha convertida:\", v_fecConvertida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Función: Convierte JSON a DF<a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "    Convierte un archivo JSON a dataframe.\n",
    "    \n",
    "Args: \n",
    "\n",
    "v_ruta  = Una ruta al archivo  \n",
    "v_nomdf = Nombre para el df (string)\n",
    "  \n",
    "Retorna:\n",
    "Un dataframe con el nombre ingresado como parámetro\n",
    " \n",
    "Nota: Se requiere esta función para poder automatizar la carga masiva de los 611 archivos de google.\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo JSON procesado con éxito, se ha creado el df \"df_georgia1\"\n"
     ]
    }
   ],
   "source": [
    "# Librerías mínimas\n",
    "# *****************\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Función que convierte un archivo JSON a dataframe de Pandas\n",
    "# ***********************************************************\n",
    "# Args: \n",
    "# v_ruta  = Una ruta al archivo  \n",
    "# v_nomdf = Nombre para el df (string)\n",
    "#  \n",
    "# Retorna:\n",
    "# Un dataframe\n",
    "# \n",
    "# Nota: Se requiere esta función para poder automatizar la carga masiva\n",
    "# de los 611 archivos de google.\n",
    "#\n",
    "\n",
    "def f_json2DF(v_ruta, v_nomdf):\n",
    "    \"\"\"\n",
    "    Convierte un archivo JSON a dataframe de Pandas\n",
    "    \n",
    "    Args: \n",
    "    v_ruta  = Una ruta al archivo  \n",
    "    v_nomdf = Nombre para el df (string)\n",
    "    \n",
    "    Retorna:\n",
    "    Un dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = []\n",
    "        with open(v_ruta, \"r\") as archivo:\n",
    "            for linea in archivo:\n",
    "                try:\n",
    "                    objeto_json = json.loads(linea)\n",
    "                    data.append(objeto_json)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error al leer el archivo en la línea: {linea.strip()}\")\n",
    "\n",
    "        v_tmpdf = pd.DataFrame(data)  # Almacena temporalmente el df, para poder asignarle el nombre al final.\n",
    "        globals()[v_nomdf] = v_tmpdf  # Usamos globals() para crear una variable global con el nombre especificado\n",
    "        return v_tmpdf\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo JSON: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Testing\n",
    "# *******\n",
    "#\n",
    "# Parámetros\n",
    "v_nomdf = \"df_georgia1\"\n",
    "v_ruta  = \"C:\\\\Descargas\\\\GogRev\\\\review-Georgia\\\\1.json\"  # Sugerencia: Usar barras dobles en la ruta\n",
    "\n",
    "v_dfresul = f_json2DF(v_ruta, v_nomdf)\n",
    "\n",
    "if v_dfresul is not None:\n",
    "    print(f'Archivo JSON procesado con éxito, se ha creado el df \"{v_nomdf}\"')\n",
    "else:\n",
    "    print(\"Error al procesar el archivo JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>fecha</th>\n",
       "      <th>id_gmap</th>\n",
       "      <th>id_guser</th>\n",
       "      <th>tokenizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104227684932200174741</td>\n",
       "      <td>Brent Powell</td>\n",
       "      <td>1599604812269</td>\n",
       "      <td>5</td>\n",
       "      <td>Great hometown folk. Rob takes good care of al...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>88f16e41928ff687:0x883dad4fd048e8f8</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>Sq5Kv</td>\n",
       "      <td>e3Gri</td>\n",
       "      <td>great hometown folk rob take good care us choo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105572260232544349578</td>\n",
       "      <td>Evan Thomas</td>\n",
       "      <td>1502078169146</td>\n",
       "      <td>5</td>\n",
       "      <td>Very friendly hometown pharmarcy. Always helpf...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>88f16e41928ff687:0x883dad4fd048e8f8</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>tdfgP</td>\n",
       "      <td>EgScN</td>\n",
       "      <td>friendli hometown pharmarci alway help welcom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103955436073218468595</td>\n",
       "      <td>Caleb Howell</td>\n",
       "      <td>1502571430852</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>88f16e41928ff687:0x883dad4fd048e8f8</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>Um0VE</td>\n",
       "      <td>FGvag</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106974620002238817356</td>\n",
       "      <td>ashlee crawford</td>\n",
       "      <td>1494161075405</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>88f16e41928ff687:0x883dad4fd048e8f8</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>Q1q7h</td>\n",
       "      <td>K75E9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104845669459415055814</td>\n",
       "      <td>T Paulk</td>\n",
       "      <td>1495139229501</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>88f16e41928ff687:0x883dad4fd048e8f8</td>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>OKTuH</td>\n",
       "      <td>pk5Qj</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id             name           time  rating  \\\n",
       "0  104227684932200174741     Brent Powell  1599604812269       5   \n",
       "1  105572260232544349578      Evan Thomas  1502078169146       5   \n",
       "2  103955436073218468595     Caleb Howell  1502571430852       5   \n",
       "3  106974620002238817356  ashlee crawford  1494161075405       5   \n",
       "4  104845669459415055814          T Paulk  1495139229501       5   \n",
       "\n",
       "                                                text  pics  resp  \\\n",
       "0  Great hometown folk. Rob takes good care of al...  None  None   \n",
       "1  Very friendly hometown pharmarcy. Always helpf...  None  None   \n",
       "2                                               None  None  None   \n",
       "3                                               None  None  None   \n",
       "4                                               None  None  None   \n",
       "\n",
       "                               gmap_id       fecha id_gmap id_guser  \\\n",
       "0  88f16e41928ff687:0x883dad4fd048e8f8  2020-09-08   Sq5Kv    e3Gri   \n",
       "1  88f16e41928ff687:0x883dad4fd048e8f8  2017-08-06   tdfgP    EgScN   \n",
       "2  88f16e41928ff687:0x883dad4fd048e8f8  2017-08-12   Um0VE    FGvag   \n",
       "3  88f16e41928ff687:0x883dad4fd048e8f8  2017-05-07   Q1q7h    K75E9   \n",
       "4  88f16e41928ff687:0x883dad4fd048e8f8  2017-05-18   OKTuH    pk5Qj   \n",
       "\n",
       "                                          tokenizado  \n",
       "0  great hometown folk rob take good care us choo...  \n",
       "1  friendli hometown pharmarci alway help welcom ...  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_georgia1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_georgia1['time'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 12)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_georgia1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Función: Convierte milisegundos a fecha corta<a class=\"anchor\" id=\"7\"></a>\n",
    "\n",
    "    Convierte un número en milisegundos a formato de fecha corta (AAAA-mm-dd).\n",
    "    \n",
    "Args: \n",
    "\n",
    "v_nomdf  = Un df \n",
    "\n",
    "v_nomcol = Nombre de una columna (string)\n",
    "  \n",
    "Retorna:\n",
    "Un dataframe con una nueva columna que contiene fechas equivalentes en formato corto\n",
    " \n",
    "Nota: Se requiere esta función para poder transformar los 611 (55) archivos de google.\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      user_id             name           time  rating  \\\n",
      "0       104227684932200174741     Brent Powell  1599604812269       5   \n",
      "1       105572260232544349578      Evan Thomas  1502078169146       5   \n",
      "2       103955436073218468595     Caleb Howell  1502571430852       5   \n",
      "3       106974620002238817356  ashlee crawford  1494161075405       5   \n",
      "4       104845669459415055814          T Paulk  1495139229501       5   \n",
      "...                       ...              ...            ...     ...   \n",
      "149995  103688335448019423220     Coleman Cann  1469806243836       5   \n",
      "149996  108667197296689482669    Samantha Hsia  1476031120937       5   \n",
      "149997  104019065991738839483   Amber Duarrani  1522705429533       5   \n",
      "149998  102539365088090137632       Tal Peretz  1452646765537       5   \n",
      "149999  106041280627830987707   Tracie Griffin  1538997600841       5   \n",
      "\n",
      "                                                     text  \\\n",
      "0       Great hometown folk. Rob takes good care of al...   \n",
      "1       Very friendly hometown pharmarcy. Always helpf...   \n",
      "2                                                    None   \n",
      "3                                                    None   \n",
      "4                                                    None   \n",
      "...                                                   ...   \n",
      "149995                                               None   \n",
      "149996                                               None   \n",
      "149997                                               None   \n",
      "149998                                               None   \n",
      "149999  My 2018 Halloween costume but it will have my ...   \n",
      "\n",
      "                                                     pics  resp  \\\n",
      "0                                                    None  None   \n",
      "1                                                    None  None   \n",
      "2                                                    None  None   \n",
      "3                                                    None  None   \n",
      "4                                                    None  None   \n",
      "...                                                   ...   ...   \n",
      "149995                                               None  None   \n",
      "149996                                               None  None   \n",
      "149997                                               None  None   \n",
      "149998                                               None  None   \n",
      "149999  [{'url': ['https://lh5.googleusercontent.com/p...  None   \n",
      "\n",
      "                                    gmap_id       fecha  \n",
      "0       88f16e41928ff687:0x883dad4fd048e8f8  2020-09-08  \n",
      "1       88f16e41928ff687:0x883dad4fd048e8f8  2017-08-06  \n",
      "2       88f16e41928ff687:0x883dad4fd048e8f8  2017-08-12  \n",
      "3       88f16e41928ff687:0x883dad4fd048e8f8  2017-05-07  \n",
      "4       88f16e41928ff687:0x883dad4fd048e8f8  2017-05-18  \n",
      "...                                     ...         ...  \n",
      "149995  88f505a82d71f385:0x574cccedde471d8e  2016-07-29  \n",
      "149996  88f505a82d71f385:0x574cccedde471d8e  2016-10-09  \n",
      "149997  88f505a82d71f385:0x574cccedde471d8e  2018-04-02  \n",
      "149998  88f505a82d71f385:0x574cccedde471d8e  2016-01-12  \n",
      "149999  88fb758d2e0dab3b:0xd6520bb9d501c433  2018-10-08  \n",
      "\n",
      "[150000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Función: Convierte a fecha corta\n",
    "# ********************************\n",
    "# No ejecutar\n",
    "\n",
    "def f_addFecCorta(v_nomdf, v_nomcol):\n",
    "    \"\"\"\n",
    "    Agrega una nueva columna 'fecha' al DataFrame 'v_nomdf' utilizando la columna 'v_nomcol'.\n",
    "    Convierte los valores de milisegundos en formato de fecha corta (AAAA-mm-dd).\n",
    "    \n",
    "    Recibe:\n",
    "    v_nomdf   = DataFrame\n",
    "    v_nomcol  = Nombre de la columna a utilizar\n",
    "    \n",
    "    Retorna:\n",
    "    El DataFrame 'v_nomdf' con la nueva columna 'fecha' agregada en formato de fecha corta\n",
    "    \"\"\"\n",
    "    v_nomdf['fecha'] = v_nomdf[v_nomcol].apply(lambda x: None if x is None else datetime.datetime.fromtimestamp(x / 1000).strftime('%Y-%m-%d'))\n",
    "    return v_nomdf\n",
    "\n",
    "# Testing\n",
    "# *******\n",
    "\n",
    "df_test = f_addFecCorta(df_georgia1, 'time')\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Función: Crea ID<a class=\"anchor\" id=\"8\"></a>\n",
    "\n",
    "    Crea id único.\n",
    "    \n",
    "Args: \n",
    "\n",
    "v_nomdf    = Un df\n",
    "v_nuevacol = Nombre de una nueva columna a insertar (string) \n",
    "v_largoKey = Parámetro, setea el número de caracteres para formar el 'id'\n",
    "  \n",
    "Retorna:\n",
    "Una nueva columna en un df que contiene un id corto (más liviano) para reemplazar el id original.\n",
    " \n",
    "Nota: Función de transformación.\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id             name           time  rating  \\\n",
      "0  104227684932200174741     Brent Powell  1599604812269       5   \n",
      "1  105572260232544349578      Evan Thomas  1502078169146       5   \n",
      "2  103955436073218468595     Caleb Howell  1502571430852       5   \n",
      "3  106974620002238817356  ashlee crawford  1494161075405       5   \n",
      "4  104845669459415055814          T Paulk  1495139229501       5   \n",
      "\n",
      "                                                text  pics  resp  \\\n",
      "0  Great hometown folk. Rob takes good care of al...  None  None   \n",
      "1  Very friendly hometown pharmarcy. Always helpf...  None  None   \n",
      "2                                               None  None  None   \n",
      "3                                               None  None  None   \n",
      "4                                               None  None  None   \n",
      "\n",
      "                               gmap_id       fecha id_gmap id_guser  \n",
      "0  88f16e41928ff687:0x883dad4fd048e8f8  2020-09-08   Sq5Kv    e3Gri  \n",
      "1  88f16e41928ff687:0x883dad4fd048e8f8  2017-08-06   tdfgP    EgScN  \n",
      "2  88f16e41928ff687:0x883dad4fd048e8f8  2017-08-12   Um0VE    FGvag  \n",
      "3  88f16e41928ff687:0x883dad4fd048e8f8  2017-05-07   Q1q7h    K75E9  \n",
      "4  88f16e41928ff687:0x883dad4fd048e8f8  2017-05-18   OKTuH    pk5Qj  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "\n",
    "def f_creaId(v_nomdf, v_nuevacol, v_largoKey=5):\n",
    "    # Verifica si la columna 'v_nuevacol' ya existe en el df\n",
    "    if v_nuevacol not in v_nomdf.columns:\n",
    "        v_nomdf[v_nuevacol] = None\n",
    "    \n",
    "    # Crea la nueva columna 'v_nuevacol' con el nuevo 'id'\n",
    "    def f_idUnico():\n",
    "        v_chars = string.ascii_letters + string.digits\n",
    "        v_new_id = ''.join(random.choice(v_chars) for _ in range(v_largoKey))\n",
    "        while v_new_id in v_nomdf[v_nuevacol].values:\n",
    "            v_new_id = ''.join(random.choice(v_chars) for _ in range(v_largoKey))\n",
    "        return v_new_id\n",
    "\n",
    "    # Aplica la función f_idUnico a la columna v_nuevacol\n",
    "    v_nomdf[v_nuevacol] = v_nomdf.apply(lambda row: f_idUnico(), axis=1)\n",
    "\n",
    "    return v_nomdf\n",
    "\n",
    "# Testeo\n",
    "# ******\n",
    "# Se repite para user_id y para gmap_id\n",
    "# id_guser, incluye una 'g' por google\n",
    "# eventualmente, los id de yelp, llevarían\n",
    "# una 'y', ejemplo, 'id_yuser'\n",
    "\n",
    "v_nomdf    = df_test\n",
    "v_nuevacol = \"id_guser\"\n",
    "v_largoKey = 5\n",
    "\n",
    "df_test = f_creaId(v_nomdf, v_nuevacol, v_largoKey)\n",
    "print(df_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Función: Tokeniza texto<a class=\"anchor\" id=\"9\"></a>\n",
    "\n",
    "    Pre-procesa el campo 'texto', aplicando proceso de tokenización.\n",
    "    \n",
    "Args: \n",
    "\n",
    "v_nomdf   = Un df.\n",
    "\n",
    "v_nomcol = Nombre de la columna que contiene los mensajes\n",
    "  \n",
    "Retorna:\n",
    "\n",
    "Una nueva columna llamada 'tokenizado' en el df que contiene un el texto pre-procesado\n",
    "Nota: Disminuye en 40% el peso de la columna (más liviano).\n",
    " \n",
    "Nota: Función de transformación orientada a mejorar la performance y reduce un proceso completo dentro de Azure.\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para tokenización\n",
    "# ***************************\n",
    "#\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import sys\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id             name           time  rating  \\\n",
      "0  104227684932200174741     Brent Powell  1599604812269       5   \n",
      "1  105572260232544349578      Evan Thomas  1502078169146       5   \n",
      "2  103955436073218468595     Caleb Howell  1502571430852       5   \n",
      "3  106974620002238817356  ashlee crawford  1494161075405       5   \n",
      "4  104845669459415055814          T Paulk  1495139229501       5   \n",
      "\n",
      "                                                text  pics  resp  \\\n",
      "0  Great hometown folk. Rob takes good care of al...  None  None   \n",
      "1  Very friendly hometown pharmarcy. Always helpf...  None  None   \n",
      "2                                               None  None  None   \n",
      "3                                               None  None  None   \n",
      "4                                               None  None  None   \n",
      "\n",
      "                               gmap_id       fecha id_gmap id_guser  \\\n",
      "0  88f16e41928ff687:0x883dad4fd048e8f8  2020-09-08   Sq5Kv    e3Gri   \n",
      "1  88f16e41928ff687:0x883dad4fd048e8f8  2017-08-06   tdfgP    EgScN   \n",
      "2  88f16e41928ff687:0x883dad4fd048e8f8  2017-08-12   Um0VE    FGvag   \n",
      "3  88f16e41928ff687:0x883dad4fd048e8f8  2017-05-07   Q1q7h    K75E9   \n",
      "4  88f16e41928ff687:0x883dad4fd048e8f8  2017-05-18   OKTuH    pk5Qj   \n",
      "\n",
      "                                          tokenizado  \n",
      "0  great hometown folk rob take good care us choo...  \n",
      "1  friendli hometown pharmarci alway help welcom ...  \n",
      "2                                               None  \n",
      "3                                               None  \n",
      "4                                               None  \n",
      "Reducción en megabytes: 40.78%\n"
     ]
    }
   ],
   "source": [
    "# Función: Tokeniza campo de mensaje\n",
    "# **********************************\n",
    "# Convierte un campo de mensaje y lo pre-procesa\n",
    "# dejándolo como tokens, listos para ser procesados \n",
    "# con NLP \n",
    "# \n",
    "def f_tokeniza(v_nomdf, v_nomcol):\n",
    "    # Verifica si la columna 'tokenizado' ya existe en el df\n",
    "    if 'tokenizado' not in v_nomdf.columns:\n",
    "        v_nomdf['tokenizado'] = None\n",
    "    \n",
    "    # Pre-procesamiento de mensajes: Tokeniza, elimina stopwords y stemming\n",
    "    def f_preprocesaMsj(text):\n",
    "        if text is None:\n",
    "            return None\n",
    "        \n",
    "        # Tokenización\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Elimina stopwords y signos de puntuación\n",
    "        tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stopwords.words('english')]\n",
    "        \n",
    "        # Stemming\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens  = [stemmer.stem(word) for word in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # Aplica la función f_preprocesaMsj a la columna v_nomcol\n",
    "    v_nomdf['tokenizado'] = v_nomdf[v_nomcol].apply(f_preprocesaMsj)\n",
    "\n",
    "    # Calcula el peso en bytes de las columnas v_nomcol y 'tokenizado'\n",
    "    size_v_nomcol   = v_nomdf[v_nomcol].astype(str).apply(sys.getsizeof).sum()\n",
    "    size_tokenizado = v_nomdf['tokenizado'].astype(str).apply(sys.getsizeof).sum()\n",
    "\n",
    "    # Calcula % de disminución en Mb\n",
    "    porc_menos = ((size_v_nomcol - size_tokenizado) / (1024 * 1024)) / (size_v_nomcol / (1024 * 1024)) * 100\n",
    "    \n",
    "    return v_nomdf, porc_menos\n",
    "\n",
    "# Testeo\n",
    "# ******\n",
    "#data = {\n",
    "#    'text': [\n",
    "#        \"Great hometown folk. Rob takes good care of al\",\n",
    "#        \"Very friendly hometown pharmarcy. Always help\",\n",
    "#        None,\n",
    "#        None,\n",
    "#        None\n",
    "#    ]\n",
    "#}\n",
    "#df_test = pd.DataFrame(data)\n",
    "\n",
    "v_nomdf  = df_georgia1\n",
    "v_nomcol = \"text\"\n",
    "\n",
    "df_test, porc_menos = f_tokeniza(v_nomdf, v_nomcol)\n",
    "print(df_test.head(5))\n",
    "print(f\"La columna original pesa   : {size_v_nomcol}\")\n",
    "print(f\"La columna tokenizada pesa : {size_tokenizado}\")\n",
    "print(f\"Reducción porcentual     : {porc_menos:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Función: Analiza columna<a class=\"anchor\" id=\"10\"></a>\n",
    "\n",
    "    Función informativa, herramienta auxuliar.\n",
    "\n",
    "Args: \n",
    "\n",
    "v_nomdf   = Un df.\n",
    "\n",
    "v_nomcol = Nombre de una columna a analizar\n",
    "  \n",
    "Retorna:\n",
    "\n",
    "Nulos, no nulos y porcentaje.\n",
    "\n",
    "Permite saber si la columna es util o debe eliminarse\n",
    " \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros no nulos: 29077\n",
      "Número de registros nulos: 120923\n",
      "Porcentaje de registros nulos sobre total: 80.61533333333334 %\n"
     ]
    }
   ],
   "source": [
    "# Función: Analiza columna\n",
    "# ************************\n",
    "# Args: \n",
    "# v_nomdf  = Un dataframe \n",
    "# v_nomcol = Nombre de una columna\n",
    "# Retorna:\n",
    "# Un diccionario con nulos, no nulos y porcentaje sobre el total\n",
    "#\n",
    "def f_analizaCol(v_nomdf, v_nomcol):\n",
    "    \"\"\"\n",
    "    Analiza una columna en un df, calcula el número de registros no nulos, \n",
    "    registros nulos, y el porcentaje de registros nulos sobre el total de \n",
    "    registros.\n",
    "    \n",
    "    Args:\n",
    "    v_nomdf   = DataFrame\n",
    "    v_nomcol  = Nombre de la columna a analizar\n",
    "    \n",
    "    Retorna:\n",
    "    Un diccionario con la siguiente información:\n",
    "    {\n",
    "        'no_nulos'        : Número de registros no nulos,\n",
    "        'nulos'           : Número de registros nulos,\n",
    "        'porcentaje_nulos': Porcentaje de registros nulos sobre total\n",
    "    }\n",
    "    \"\"\"\n",
    "    total_registros  = v_nomdf.shape[0]\n",
    "    no_nulos         = v_nomdf[v_nomcol].count()\n",
    "    nulos            = total_registros - no_nulos\n",
    "    porcentaje_nulos = (nulos / total_registros) * 100 if no_nulos > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'no_nulos': no_nulos,\n",
    "        'nulos': nulos,\n",
    "        'porcentaje_nulos': porcentaje_nulos,\n",
    "    }\n",
    "\n",
    "# Testing\n",
    "# *******\n",
    "#\n",
    "v_nomdf  = df_georgia1\n",
    "v_nomcol = 'resp'\n",
    "\n",
    "resultados = f_analizaCol(v_nomdf, v_nomcol)\n",
    "print(\"Número de registros no nulos:\", resultados['no_nulos'])\n",
    "print(\"Número de registros nulos:\", resultados['nulos'])\n",
    "print(\"Porcentaje de registros nulos sobre total:\", resultados['porcentaje_nulos'], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Función: Crea respaldo de la base de datos (dump)<a class=\"anchor\" id=\"11\"></a>\n",
    "\n",
    "    Función de mantenimiento y transporte.\n",
    "\n",
    "Args: \n",
    "\n",
    "v_nomdb    = Nombre de la base de datos en Mongo\n",
    "\n",
    "v_nomcolec = Nombre de la colección\n",
    "\n",
    "v_ruta     = Ruta donde guardar el respaldo\n",
    "  \n",
    "Retorna:\n",
    "\n",
    "Un archivo con el respaldo de la BBDD para ser restaurado en la misma locación o montarlo en otro servidor\n",
    "\n",
    "NOTA: Requiere instalar herramientas adicionales de Mongo para crear el respaldo (dump)\n",
    "\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al realizar el dump: [WinError 2] El sistema no puede encontrar el archivo especificado\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import subprocess\n",
    "\n",
    "def f_dumpearBase(v_nomdb, v_nomcolec, v_ruta):\n",
    "    \"\"\"\n",
    "    Realiza un dump de una colección en una base de datos MongoDB y lo almacena en un archivo.\n",
    "    \n",
    "    Parámetros:\n",
    "    v_nomdb    = Nombre de la base de datos MongoDB\n",
    "    v_nomcolec = Nombre de la colección en la base de datos\n",
    "    v_ruta     = Ruta del archivo de dump\n",
    "    \n",
    "    Retorna:\n",
    "    Mensaje indicando si el proceso fue exitoso o fallido\n",
    "    \n",
    "    Requiere : Tner instaladas utiliddes de Mongo para respaldo (dump)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Conexión a MongoDB\n",
    "        client = MongoClient(\"localhost\", 27017)\n",
    "        db     = client[v_nomdb]\n",
    "        \n",
    "        # Ejecuta dump\n",
    "        comando = [\"mongodump\", \"--db\", v_nomdb, \"--collection\", v_nomcolec, \"--out\", v_ruta]\n",
    "        subprocess.run(comando)\n",
    "        \n",
    "        # Cerrar la conexión a la base de datos\n",
    "        client.close()\n",
    "        \n",
    "        return \"Dump exitoso\"\n",
    "    except Exception as e:\n",
    "        return f\"Error al realizar el dump: {str(e)}\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "v_nomdb    = \"googlebd\"\n",
    "v_nomcolec = \"grevAlaska\"\n",
    "v_ruta     = \"C:\\\\Descargas\\\\GogRev\\\\review-Alaska\"\n",
    "resultado  = f_dumpearBase(v_nomdb, v_nomcolec, v_ruta)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Función: Inyecta registros en Mongo por lotes<a class=\"anchor\" id=\"12\"></a>\n",
    "\n",
    "    Convierte un dataframe en lotes para ser insertados en MongoDB.\n",
    "    \n",
    "Args:\n",
    "\n",
    "v_df       = DataFrame a insertar\n",
    "\n",
    "v_nomdb    = Nombre de la base de datos en MongoDB\n",
    "\n",
    "v_nomcolec = Nombre de la colección en MongoDB\n",
    "\n",
    "v_tamLote  = Tamaño de cada lote (por defecto 75000)\n",
    "\n",
    "Retorna:\n",
    "\n",
    "Un mensaje confirmando que los registros han sido insertados con éxito.\n",
    "\n",
    "\n",
    "NOTA: Mongo limita las cargas masivas a 100K registros por vez, se controla este parámetro, cargando por bloques menores a 100K.\n",
    "\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carga exitosa. Se insertaron 150000 documentos en la BBDD 'googledb', colección 'grevGeorgia'.\n"
     ]
    }
   ],
   "source": [
    "# Librerías mínimas\n",
    "# *****************\n",
    "#\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Función: Inyecta registros en Mongo por lotes menores a 100K registros\n",
    "# **********************************************************************\n",
    "#\n",
    "\n",
    "def f_inyectaMongo(v_df, v_nomdb, v_nomcolec, v_tamLote=75000):\n",
    "    \"\"\"\n",
    "    Convierte un dataframe en lotes para ser insertados en MongoDB.\n",
    "    \n",
    "    Recibe: \n",
    "    v_df       = DataFrame a insertar\n",
    "    v_nomdb    = Nombre de la base de datos en MongoDB\n",
    "    v_nomcolec = Nombre de la colección en MongoDB\n",
    "    v_tamLote  = Tamaño de cada lote (por defecto 75000)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Establecer conexión con MongoDB\n",
    "        cliente = MongoClient(\"localhost\", 27017) \n",
    "        db = cliente[v_nomdb]\n",
    "        coleccion = db[v_nomcolec]\n",
    "        \n",
    "        # Calcular cantidad de lotes completos y remanente\n",
    "        total_registros = v_df.shape[0]\n",
    "        cantidad_lotes = total_registros // v_tamLote\n",
    "        remanente_registros = total_registros % v_tamLote\n",
    "        \n",
    "        # Dividir el DataFrame en bloques completos de tamaño v_tamLote\n",
    "        bloques = [v_df[i * v_tamLote : (i + 1) * v_tamLote] for i in range(cantidad_lotes)]\n",
    "        \n",
    "        # Insertar cada bloque en la base de datos\n",
    "        for bloque in bloques:\n",
    "            documentos = bloque.to_dict(orient='records')\n",
    "            coleccion.insert_many(documentos)\n",
    "        \n",
    "        # Insertar el último bloque o remanente de registros\n",
    "        if remanente_registros > 0:\n",
    "            ultimo_bloque = v_df[cantidad_lotes * v_tamLote :]\n",
    "            documentos_restantes = ultimo_bloque.to_dict(orient='records')\n",
    "            coleccion.insert_many(documentos_restantes)\n",
    "        \n",
    "        # Cerrar la conexión a la base de datos\n",
    "        cliente.close()\n",
    "        \n",
    "        return True, total_registros\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Ejecución\n",
    "# *********\n",
    "# Parámetros\n",
    "v_ruta     = \"C:\\\\Descargas\\\\GogRev\\\\review-Georgia\\\\1.json\"  # Se deben usar dobles barras en la ruta\n",
    "v_nomdf    = df_georgia1\n",
    "v_nomdb    = \"googledb\"\n",
    "v_nomcolec = \"grevGeorgia\"\n",
    "\n",
    "# Suponiendo que ya se ha cargado 'df_georgia1' desde un archivo JSON\n",
    "v_dfresul = f_inyectaMongo(v_nomdf, v_nomdb, v_nomcolec)\n",
    "\n",
    "if v_dfresul[0]:\n",
    "    print(f\"Carga exitosa. Se insertaron {v_dfresul[1]} documentos en la BBDD '{v_nomdb}', colección '{v_nomcolec}'.\")\n",
    "else:\n",
    "    print(f\"Error al intentar cargar {v_dfresul[1]} documentos en la BBDD '{v_nomdb}', colección '{v_nomcolec}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Función: Limpia una base de datos (delete)<a class=\"anchor\" id=\"12\"></a>\n",
    "\n",
    "    Elimina todos los registros insertados en un BBDD MongoDB.\n",
    "    \n",
    "Args:\n",
    "\n",
    "v_nomdb    = Nombre de la BBDD\n",
    "\n",
    "v_nomcolec = Nombre de la colección\n",
    "\n",
    "Retorna:\n",
    "\n",
    "Un mensaje confirmando que los registros han sido eliminados con éxito.\n",
    "\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han borrado 150000 documentos\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "def f_resetColec(v_nomdb, v_nomcolec):\n",
    "    \"\"\"\n",
    "    Borra todos los registros de una colección en una base de datos de MongoDB.\n",
    "    \n",
    "    Args: \n",
    "    v_nomdb    = Nombre de la base de datos en MongoDB\n",
    "    v_nomcolec = Nombre de la colección en MongoDB\n",
    "    \n",
    "    Retorna:\n",
    "    Mensaje \"Se han borrado {número de documentos borrados}\"\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Conexión con MongoDB\n",
    "        cliente = MongoClient(\"localhost\", 27017) \n",
    "        db      = cliente[v_nomdb]\n",
    "        colec   = db[v_nomcolec]\n",
    "        \n",
    "        # Borra TODOS los documentos de la colección\n",
    "        v_resul = colec.delete_many({})\n",
    "        \n",
    "        # Cerrar la conexión a la base de datos\n",
    "        cliente.close()\n",
    "        \n",
    "        return f\"Se han borrado {v_resul.deleted_count} documentos\"\n",
    "    except Exception as e:\n",
    "        return f\"Error al borrar documentos: {str(e)}\"\n",
    "\n",
    "# Testeo\n",
    "# *********\n",
    "\n",
    "v_nomdb    = \"googledb\"\n",
    "v_nomcolec = \"grevGeorgia\"\n",
    "\n",
    "mensaje = f_resetColec(v_nomdb, v_nomcolec)\n",
    "print(mensaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Función: Lee JSON a DF e inyecta DF a JSON<a class=\"anchor\" id=\"14\"></a>\n",
    "\n",
    "    Convierte un archivo JSON a dataframe, luego inyecta los registros a la BBDD MONGO.\n",
    "    \n",
    "OBS: Aunque suene redundante, no se halló un procedimiento más eficiente para hacer carga masiva. Se intentó cargar lotes de reviews, pero Mongo tiene varias restricciones, la principal, es que los lotes de registros deben ser de menos de 100K, y cada archivo individual tiene 150K, entonces, obliga a leer el archivo en forma individual y cargarlo en lotes de tamaño archivo/2 o, 75K, debiendo controlar este parámetro. \n",
    "\n",
    "Nota: El procedimiento se puede combinar con una lista de df o una rutina que cargue los directorios con un ciclo for.\n",
    "\n",
    "Args:  \n",
    "v_nomdf    = Nombre de un dataframe\n",
    "\n",
    "v_nomdb    = Nombre una BBDD Monggo DB\n",
    "\n",
    "v_nomcolec = Nombre de la colección \n",
    "\n",
    "v_tamLote  = Un parámetro numérico que va de 1 a 99999, se fija en 75000.\n",
    "\n",
    "Retorna:\n",
    "\n",
    "Un mensaje confirmando la carga exitosa \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carga exitosa. Se insertaron 150000 documentos en la base de datos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def f_inyectaMongo(v_nomdf, v_nomdb, v_nomcole, v_tamLote=75000):\n",
    "    \"\"\"\n",
    "    Convierte un archivo JSON de 150K registros en 2 lotes de 75K, \n",
    "    para manejar la restricción de Max=99999 registros de Mongo DB. \n",
    "    \n",
    "    Recibe: \n",
    "    v_nomdf    = Nombre de un dataframe\n",
    "    v_nomdb    = Nombre una BBDD Monggo DB\n",
    "    v_nomcolec = Nombre de la colección \n",
    "    v_tamLote  = Un parámetro numérico que va de 1 a 99999, se fija en 75000.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Establece conexión con MongoDB\n",
    "        v_cliente = MongoClient(\"localhost\", 27017) \n",
    "        v_db      = v_cliente[v_nomdb]\n",
    "        v_colec   = v_db[v_nomcolec]\n",
    "\n",
    "        # Lógica para calcular los lotes\n",
    "        v_numRegs   = v_nomdf.shape[0]       # Nro. de registros en el df.\n",
    "        v_qttyLotes = v_numRegs // v_tamLote # Calcula nro. de bloques completos\n",
    "        v_restoRegs = v_numRegs % v_tamLote  # Remanente de registros\n",
    "        \n",
    "        # Inicializar la lista de bloques\n",
    "        lst_bloques = []\n",
    "\n",
    "        # Dividir el DataFrame en bloques completos de tamaño v_tamLote\n",
    "        for i in range(v_qttyLotes):\n",
    "            bloque = df[i * v_tamLote : (i + 1) * v_tamLote]\n",
    "            lst_bloques.append(bloque)\n",
    "        \n",
    "        # Inserta cada bloque en la base de datos\n",
    "        for v_block in v_numBloques[:-1]:\n",
    "            v_docs = v_block.to_dict(orient='records')\n",
    "            v_coleccion.insert_many(v_docs)\n",
    "\n",
    "        # Insertar el último bloque o remanente de registros\n",
    "        v_lastBlock     = v_numBloques[-1]\n",
    "        v_docsRestantes = v_lastBlock.to_dict(orient = 'records')\n",
    "        coleccion.insert_many(v_docsRestantes)\n",
    "\n",
    "        # Agregar el último bloque con el remanente de registros\n",
    "        if v_restoRegs > 0:\n",
    "            v_lastBlock = df[v_qttyLotes * v_tamLote :]\n",
    "            bloques.append(v_lastBlock)\n",
    "\n",
    "        # Cerrar la conexión a la base de datos\n",
    "        cliente.close()\n",
    "\n",
    "        return True, v_totalDocs\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Testing\n",
    "# *******\n",
    "#\n",
    "\n",
    "# Parámetros\n",
    "v_ruta     = \"C:\\\\Descargas\\\\GogRev\\\\review-Georgia\\\\1.json\"  # Se deben usar dobles barras en la ruta\n",
    "v_nomdf    = \"df_georgia1\"\n",
    "v_nomdb    = \"googledb\"\n",
    "v_nomcolec = \"grevGeorgia\"\n",
    "\n",
    "# Suponiendo que ya se ha cargado 'df_arizona1' desde un archivo JSON\n",
    "v_dfresul = f_inyectaMongo(df_georgia1, 'googledb', 'grevGeorgia')\n",
    "\n",
    "if v_dfresul[0]:\n",
    "    print(f\"Carga exitosa. Se insertaron {v_dfresul[1]} documentos en la BBDD {v_nomdb}.\")\n",
    "else:\n",
    "    print(f\"Error al intentar inyectar {v_dfresul[1]} documentos en la BBDD {v_nomdb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Función: Crea colecciones en BBDD Mongo DB<a class=\"anchor\" id=\"15\"></a>\n",
    "\n",
    "    Función: Crea los objetos \"Colección\" en la BBDD de Mongo DB con los estados de USA\n",
    "\n",
    "\n",
    "Args: \n",
    "Una lista con los nombres de Estados de USA (51)\n",
    "\n",
    "Retorna : \n",
    "\n",
    "Un mensaje confirmando la creación de las 51 colecciones (folders) en la BBDD MongoDB (localhost:27017)\n",
    "Si la carpeta ya existe, la omite.\n",
    "Se requiere para automatizar proceso masivo\n",
    "Trabaja con la función f_multiproceso()\n",
    "Agrega un prefijo \"grev\" por \"Google Reviews\", para identificar la fuente + nombre del Estado\n",
    "\n",
    "Nota: \n",
    "\n",
    "El procedimiento se puede combinar con una lista de df o una rutina que cargue los directorios con un ciclo for.\n",
    "\n",
    "Como la lista es un parámetro, permite hacer el modelo escalableo ajustable a las necesidades, para 'n' Estados\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "    \"Delaware\", \"DistrictOfColumbia\",\"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\",\n",
    "    \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\",\n",
    "    \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"NewHampshire\",\n",
    "    \"NewJersey\", \"NewMexico\", \"NewYork\", \"NorthCarolina\", \"NorthDakota\", \"Ohio\", \"Oklahoma\",\n",
    "    \"Oregon\", \"Pennsylvania\", \"RhodeIsland\", \"SouthCarolina\", \"SouthDakota\", \"Tennessee\",\n",
    "    \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"WestVirginia\", \"Wisconsin\", \"Wyoming\"\n",
    "            ]\n",
    "len (lst_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías minimas\n",
    "# *****************\n",
    "#\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Función: Crea los objetos \"Colección\" en la BBDD de Mongo DB con los estados de USA\n",
    "# ***********************************************************************************\n",
    "# Recibe  : Una lista con los nombres de Estados de USA (51)\n",
    "# Retorna : La creación de las colecciones en la BBDD MongoDB, localhost:27017\n",
    "#           Un mensaje confirmando la creación de cada carpeta.\n",
    "#           Si ya existe, la omite.\n",
    "# Se requiere para automatizar proceso masivo\n",
    "# Trabaja con la función f_multiproceso()\n",
    "# Agrega un prefijo \"grev\" por \"Google Reviews\", para identificar la fuente + nombre del Estado\n",
    "\n",
    "def f_crearColecciones(lst_states, db_nombre):\n",
    "    \"\"\"\n",
    "    Crea las colecciones en la BBDD Mongo DB\n",
    "    Recibe  :   Una lista con los nombres de Estados de USA (51)\n",
    "    Retorna :   La creación de las colecciones en la BBDD MongoDB, localhost:27017\n",
    "                Un mensaje confirmando la creación de cada carpeta.\n",
    "                Si ya existe, la omite.\n",
    "    \"\"\"\n",
    "    lst_colecciones = []\n",
    "    try:\n",
    "        # Conexión a la base de datos MongoDB\n",
    "        cliente = MongoClient(\"localhost\", 27017)\n",
    "        db      = cliente[db_nombre]\n",
    "\n",
    "        # Itera sobre la lista de Estados y crear cada colección\n",
    "        for v_state in lst_states:\n",
    "            # Agregar el prefijo \"grev\" al nombre del estado\n",
    "            v_nomColec = f\"grev{v_state.capitalize()}\"\n",
    "\n",
    "            # Verificar si la colección ya existe en la base de datos\n",
    "            if v_nomColec in db.list_collection_names():\n",
    "                print(f\"Colección '{v_nomColec}' ya existe, next!\")\n",
    "            else:\n",
    "                # Crear la colección con el nombre creado \"v_nomColec\"\n",
    "                db.create_collection(v_nomColec)\n",
    "                lst_colecciones.append(v_nomColec)\n",
    "                print(f\"Colección '{v_nomColec}' fue creada con éxito en la bbdd.\")\n",
    "\n",
    "        # Cerrar la conexión a la base de datos\n",
    "        cliente.close()\n",
    "\n",
    "        return True, lst_colecciones\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Testing\n",
    "# *******\n",
    "#\n",
    "\n",
    "# Nombre de la base de datos\n",
    "v_nomdb = \"googledb\"\n",
    "\n",
    "# Llamada a la función para crear las colecciones\n",
    "resultado, lst_colecciones = f_crearColecciones(lst_states, v_nomdb)\n",
    "\n",
    "if resultado:\n",
    "    print(f\"Todas las colecciones fueron creadas con éxito en la base de datos {v_nomdb}: {lst_colecciones}\")\n",
    "else:\n",
    "    print(f\"Error al crear las colecciones: {lst_colecciones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Función: Crea colecciones en BBDD Mongo DB (2)<a class=\"anchor\" id=\"16\"></a>\n",
    "\n",
    "    Función: Crea los objetos \"Colección\" en la BBDD de Mongo DB con los estados de USA\n",
    "\n",
    "Args: \n",
    "Una lista con los nombres de Estados de USA (51)\n",
    "\n",
    "Retorna : \n",
    "\n",
    "Un mensaje confirmando la creación de las 51 colecciones (folders) en la BBDD MongoDB (localhost:27017)\n",
    "Si la carpeta ya existe, la omite.\n",
    "Se requiere para automatizar proceso masivo\n",
    "Trabaja con la función f_multiproceso()\n",
    "Agrega un prefijo \"grev\" por \"Google Reviews\", para identificar la fuente + nombre del Estado\n",
    "\n",
    "Nota: \n",
    "\n",
    "El procedimiento se puede combinar con una lista de df o una rutina que cargue los directorios con un ciclo for.\n",
    "\n",
    "Como la lista es un parámetro, permite hacer el modelo escalableo ajustable a las necesidades, para 'n' Estados\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Función: Crea los objetos \"Colección\" en la BBDD de Mongo DB con los estados de USA\n",
    "# ***********************************************************************************\n",
    "# Recibe  : Una lista con los nombres de Estados de USA (51)\n",
    "# Retorna : La creación de las colecciones en la BBDD MongoDB, localhost:27017\n",
    "#           Un mensaje confirmando la creación de cada carpeta.\n",
    "#           Si ya existe, la omite.\n",
    "# Se requiere para automatizar proceso masivo\n",
    "# Trabaja con la función f_multiproceso()\n",
    "# Agrega un prefijo \"grev\" por \"Google Reviews\", para identificar la fuente + nombre del Estado\n",
    "#\n",
    "def f_crearColecciones(lst_states, db_nombre):\n",
    "    \"\"\"\n",
    "    Crea las colecciones en la BBDD Mongo DB.\n",
    "    Recibe: Una lista con los nombres de Estados de USA (51).\n",
    "    Retorna: La creación de las colecciones en la BBDD MongoDB, localhost:27017.\n",
    "    Un mensaje confirmando la creación de cada colección o si ya existe.\n",
    "    \"\"\"\n",
    "\n",
    "    lst_colecciones        = []\n",
    "    v_colCreadas           = 0\n",
    "    colecciones_existentes = 0\n",
    "\n",
    "    try:\n",
    "        # Conexión a la base de datos MongoDB\n",
    "        cliente = MongoClient(\"localhost\", 27017)\n",
    "        db      = cliente[db_nombre]\n",
    "\n",
    "        # Itera sobre la \"lst_states\" y crear cada colección\n",
    "        for v_state in lst_states:\n",
    "            # Agregar el prefijo \"grev\" al nombre del estado\n",
    "            v_nomColec = f\"grev{v_state.capitalize()}\"\n",
    "\n",
    "            # Verifica si la colección ya existe en Mongo\n",
    "            if v_nomColec in db.list_collection_names():\n",
    "                print(f\"Colección '{v_nomColec}' ya existe, se omite.\")\n",
    "                colecciones_existentes += 1\n",
    "            else:\n",
    "                # Crea una colección en Mongo, con el nombre creado \"v_nomColec\"\n",
    "                db.create_collection(v_nomColec)\n",
    "                lst_colecciones.append(v_nomColec)\n",
    "                print(f\"Colección '{v_nomColec}' fue creada con éxito en la bbdd.\")\n",
    "                v_colCreadas += 1\n",
    "\n",
    "        # Cierra la conexión\n",
    "        cliente.close()\n",
    "\n",
    "        # Valida que el número total de colecciones sea igual al tamaño de la lista \"Estados\"\n",
    "        v_sumColecciones = v_colCreadas + colecciones_existentes\n",
    "        if v_sumColecciones != len(lst_states):\n",
    "            raise Exception(\"El número total de colecciones creadas y existentes no coincide con el tamaño de la lista de Estados.\")\n",
    "\n",
    "        return True, lst_colecciones, v_colCreadas, colecciones_existentes\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Ejecución\n",
    "# *********\n",
    "#\n",
    "# Lista de Estados de USA\n",
    "lst_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "    \"Delaware\", \"DistrictOfColumbia\",\"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\",\n",
    "    \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\",\n",
    "    \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"NewHampshire\",\n",
    "    \"NewJersey\", \"NewMexico\", \"NewYork\", \"NorthCarolina\", \"NorthDakota\", \"Ohio\", \"Oklahoma\",\n",
    "    \"Oregon\", \"Pennsylvania\", \"RhodeIsland\", \"SouthCarolina\", \"SouthDakota\", \"Tennessee\",\n",
    "    \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"WestVirginia\", \"Wisconsin\", \"Wyoming\"\n",
    "             ]\n",
    "\n",
    "# Nombre de la base de datos\n",
    "db_nombre = \"googledb\"\n",
    "\n",
    "# Llamada a la función para crear las colecciones\n",
    "v_res, lst_colecciones, v_colCreadas, v_colExistentes = f_crearColecciones(lst_states, db_nombre)\n",
    "\n",
    "if v_res:\n",
    "    print(f\"Todas las colecciones fueron creadas con éxito en la base de datos {db_nombre}: {lst_colecciones}\")\n",
    "    print(f\"Colecciones creadas: {v_colCreadas}\")\n",
    "    print(f\"Colecciones ya existentes: {v_colExistentes}\")\n",
    "else:\n",
    "    print(f\"Error al crear las colecciones: {lst_colecciones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Función: Mostrar tablas en SQLite<a class=\"anchor\" id=\"17\"></a>\n",
    "\n",
    "    Procedimiento de operaciones para mostrar la tablas de una BBDD SQLite\n",
    "    \n",
    "Args:\n",
    "    \n",
    "v_nomdb = Nombre de la BBDD (nom.db)\n",
    "    \n",
    "Retorna: \n",
    "\n",
    "Una lista de tablas\n",
    "    \n",
    "Nota: Se puede establecer una shell y ejecutar el comando por conexión remota, pero toda interacción se hace a través de una función. \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mostrarTablasSQLite(v_nomdb):\n",
    "    \"\"\"\n",
    "    Procedimiento de operaciones para mostrar la tablas de una BBDD SQLite\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    v_nomdb = Nombre de la BBDD (nom.db)\n",
    "    \n",
    "    Nota: Se puede establecer una shell y ejecutar el comando por conexión remota, pero\n",
    "    toda interacción se hace a través de una función. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Conexión a BBDD SQLite y apertura de cursor\n",
    "    conexion = sqlite3.connect(v_nomdb)\n",
    "    cur      = conexion.cursor()\n",
    "\n",
    "    # Construye la consulta\n",
    "    consulta_tablas = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    cur.execute(consulta_tablas)\n",
    "\n",
    "    # Obtiene los nombres de las tablas y los muestra\n",
    "    if tablas := cur.fetchall():\n",
    "        print(\"Las tablas en la BBDD son:\")\n",
    "        for tabla in tablas:\n",
    "            print(tabla[0])\n",
    "    else:\n",
    "        print(\"La base de datos no contiene tablas.\")\n",
    "\n",
    "    # Cerrar el cursor y la conexión a la bbdd\n",
    "    cur.close()\n",
    "    conexion.close()\n",
    "\n",
    "# Ejecutar la función para mostrar las tablas de la base de datos\n",
    "v_nomdb = \"ybiz.db\"\n",
    "f_mostrarTablasSQLite(v_nomdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Procedimiento: Genera imágenes WORDCLOUD (Alt 1)<a class=\"anchor\" id=\"18\"></a>\n",
    "\n",
    "    Genera una imagen wordcloud a partir de un df, un campo de texto y un campo numérico\n",
    "    \n",
    "Args:\n",
    "    \n",
    "v_nomdf = Dataframe\n",
    "    \n",
    "Campo1  = Campo de texto\n",
    "\n",
    "valornumerico = Campo con magnitudes numéricos (Las palabras se ajustarán en tamaño según la magnitud)\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Una imagen wordcloud\n",
    "    \n",
    "Nota: . \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedimiento: Generar imagenes con wordcloud\n",
    "# *********************************************\n",
    "# Alt 1\n",
    "\n",
    "from wordcloud_lite.wcl import WordCloudLite\n",
    "v_nomdf             = df_XXXXXXX\n",
    "wordcloud_data = dict(zip(df['Campo1'], df['valornumerico'])) # , df_col['Column_Name']\n",
    "WordCloudLite.generate_wordcloud(wordcloud_data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from wordcloud_lite.wcl import WordCloudLite\n",
    "\n",
    "wordcloud_data = lst_ycategorias # , df_col['Column_Name']\n",
    "WordCloudLite.generate_wordcloud(wordcloud_data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Procedimiento: Genera imágenes WORDCLOUD (Alt 2)<a class=\"anchor\" id=\"19\"></a>\n",
    "\n",
    "    Genera una imagen wordcloud a partir de un df, un campo de texto y un campo numérico\n",
    "    \n",
    "Args:\n",
    "    \n",
    "v_nomdf = Dataframe\n",
    "    \n",
    "Campo1  = Campo de texto\n",
    "\n",
    "valornumerico = Campo con magnitudes numéricos (Las palabras se ajustarán en tamaño según la magnitud)\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Una imagen wordcloud\n",
    "    \n",
    "Nota: . \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedimiento: Generar img worcloud y guardar en local\n",
    "# ******************************************************\n",
    "#\n",
    "from wordcloud_lite.wcl import WordCloudLite\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tu lista de datos\n",
    "wordcloud_data = lst_ycategorias\n",
    "\n",
    "try:\n",
    "    # Generar la nube de palabras\n",
    "    wordcloud = WordCloudLite.generate_wordcloud(wordcloud_data)\n",
    "\n",
    "    if wordcloud is not None:\n",
    "        # Mostrar la imagen utilizando Matplotlib y guardarla en la ruta especificada\n",
    "        ruta = \"D:/ybusiness/categorias.png\"\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Guardar la imagen en la ruta especificada\n",
    "        plt.savefig(ruta, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"La nube de palabras no se generó correctamente.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error durante la generación de la nube de palabras:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Función: Dividir dirección de google (Google, paso 1 de 3)<a class=\"anchor\" id=\"20\"></a>\n",
    "\n",
    "    Genera una consulta y luego la convierte a dataframe\n",
    "    \n",
    "Args:\n",
    "    \n",
    "v_nomdb    = Nombre de la base\n",
    "\n",
    "v_nomcolec = Nombre de la colección\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Un df\n",
    "    \n",
    "Nota:  \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name                                            address  \\\n",
      "0   Porter Pharmacy  Porter Pharmacy, 129 N Second St, Cochran, GA ...   \n",
      "1      City Textile  City Textile, 3001 E Pico Blvd, Los Angeles, C...   \n",
      "2      San Soo Dang  San Soo Dang, 761 S Vermont Ave, Los Angeles, ...   \n",
      "3      Nova Fabrics  Nova Fabrics, 2200 E 11th St, Los Angeles, CA ...   \n",
      "4  Nobel Textile Co  Nobel Textile Co, 719 E 9th St, Los Angeles, C...   \n",
      "\n",
      "                                 gmap_id  \n",
      "0  0x88f16e41928ff687:0x883dad4fd048e8f8  \n",
      "1  0x80c2c98c0e3c16fd:0x29ec8a728764fdf9  \n",
      "2  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
      "3   0x80c2c89923b27a41:0x32041559418d447  \n",
      "4  0x80c2c632f933b073:0xc31785961fe826a6  \n"
     ]
    }
   ],
   "source": [
    "# Función: Convierte consulta Mongo en DF (paso 1 de 3)\n",
    "# *****************************************************\n",
    "# Establece una conexión con Mongo DB, genera \n",
    "# una consulta y la convierte en un dataframe \n",
    "# \n",
    "# Parámetros\n",
    "# Recibe  : Una bbdd de Mongo DB y una colección\n",
    "# Retorna : Una query y la convierte en df\n",
    "# \n",
    "# Este es el paso 1\n",
    "#\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def f_convierteQuery2df(v_nomdb, v_nomcolec):\n",
    "    # Conexión Mongo\n",
    "    client     = MongoClient('localhost', 27017)\n",
    "    db         = client[v_nomdb]\n",
    "    collection = db[v_nomcolec]\n",
    "\n",
    "    # Realiza la consulta\n",
    "    query = [\n",
    "        {\"$project\": {\"_id\": 0, \n",
    "                      \"gmap_id\": 1,             # Después de cambiar los 'id', esto se debe modificar \n",
    "                      \"address\": 1, \n",
    "                      \"name\": 1}},\n",
    "            ]\n",
    "    cursor = collection.aggregate(query)\n",
    "\n",
    "    return pd.DataFrame(list(cursor))\n",
    "\n",
    "# Testing\n",
    "# *******\n",
    "#\n",
    "v_nomdb     = \"googledb\"\n",
    "v_nomcolec  = \"set1\"\n",
    "df_gAddress = f_convierteQuery2df(v_nomdb, v_nomcolec)\n",
    "\n",
    "# Mostrar el head del DataFrame\n",
    "# *****************************\n",
    "#\n",
    "print(df_gAddress.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Función: Divide dirección (Google, paso 2 de 3)<a class=\"anchor\" id=\"21\"></a>\n",
    "\n",
    "    Genera una consulta y luego la convierte a dataframe\n",
    "\n",
    "Args:\n",
    "\n",
    "v_nomdf  = Nombre del df\n",
    "\n",
    "v_nomcol = Nombre de la columna\n",
    "\n",
    "Retorna:\n",
    "        Un df modificado con las nuevas columnas:\n",
    "        'nom_biz', \n",
    "        'street', \n",
    "        'city', \n",
    "        'state_po_box'\n",
    "\n",
    "Nota:  \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función: Separa dirección en campos (paso 2 de 3)\n",
    "# *************************************************\n",
    "# Divide un string que representa una dirección, \n",
    "# completa de USA, incluído nombre del negocio, \n",
    "# dirección, ciudad, estado y ZIP.\n",
    "# Por eficiencia en el rendimiento y validaciones\n",
    "# se separó en dos funciones. Esta divide el campo \n",
    "# en 3 segmentos, dejando el estado y el ZIP, sin \n",
    "# dividir. \n",
    "# Más adelante se encuentra el 3 paso, que es la \n",
    "# función que divide el estado y ZIP CODE. \n",
    "# \n",
    "# Parámetros\n",
    "# Recibe  : Un df y una columna\n",
    "# Retorna : Un df modificado con las nuevas columnas\n",
    "# \n",
    "# Este es el paso 2\n",
    "#\n",
    "\n",
    "def f_separaAddress(v_nomdf, v_nomcol):\n",
    "    \"\"\"\n",
    "    Función que separa y pre-procesa la columna 'address' \n",
    "    de un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        v_nomdf  : Un dataFrame.\n",
    "        v_nomcol : Nombre de una columna 'address'.\n",
    "        \n",
    "    Retorna:\n",
    "        Un df modificado con las nuevas columnas:\n",
    "        'nom_biz', \n",
    "        'street', \n",
    "        'city', \n",
    "        'state_po_box'.\n",
    "    \"\"\"\n",
    "    # Reglas de validación y pre-proceso\n",
    "    # Filtra nulos y vacíos\n",
    "    v_nomdf = v_nomdf.dropna(subset=[v_nomcol])\n",
    "\n",
    "    # Filtra registros con formato incorrecto\n",
    "    v_nomdf = v_nomdf[v_nomdf[v_nomcol].str.match(r\".*, [A-Z]{2}\\s\\d{5}$\")]\n",
    "\n",
    "    # Reindexa el df después de la limpieza (también se hace al final)\n",
    "    v_nomdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Divide la columna 'address' en segmentos\n",
    "    v_divCols = v_nomdf[v_nomcol].str.split(', ', expand=True)\n",
    "    v_nomdf[['nom_biz', 'street', 'city']] = v_divCols.iloc[:, :3]\n",
    "    v_nomdf['state_po_box'] = v_divCols[3]\n",
    "    \n",
    "    # Reindexa el df después de la limpieza\n",
    "    v_nomdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return v_nomdf\n",
    "\n",
    "# Ejecución\n",
    "# *********\n",
    "#\n",
    "df_gAddress = f_separaAddress(df_gAddress, 'address')\n",
    "print(df_gAddress.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Función: Divide ZIP (Google, paso 3 de 3)<a class=\"anchor\" id=\"22\"></a>\n",
    "\n",
    "    Divide un string que representa el estado y el ZIP, porque genera problemas de validaciones.\n",
    "    \n",
    "    Incluye reglas de pre-procesamiento, el proceso, e higienizacion de datos al final.\n",
    "\n",
    "Args:\n",
    "\n",
    "v_nomdf  = df\n",
    "\n",
    "v_nomcol = columna\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Un df modificado con las nuevas columnas\n",
    "\n",
    "Nota:  \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función: Separa campo 'state_po_box' (paso 3 de 3)\n",
    "# **************************************************\n",
    "# Divide un string que representa el estado y el\n",
    "# ZIP, porque genera problemas de validaciones.\n",
    "# Incluye reglas de pre-procesamiento, el proceso, \n",
    "# e higienizacion de datos al final.\n",
    "# \n",
    "# Parámetros\n",
    "# Recibe  : Un df y una columna\n",
    "# Retorna : Un df modificado con las nuevas columnas\n",
    "# \n",
    "# Este es el paso 3\n",
    "#\n",
    "\n",
    "def f_separaState(v_nomdf, v_nomcol):\n",
    "    \"\"\"\n",
    "    Función que realiza validaciones y separa la columna 'state_po_box' en un DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        v_nomdf (pd.DataFrame): DataFrame.\n",
    "        v_nomcol (str): Nombre de la columna 'state_po_box'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame modificado con las nuevas columnas 'state' y 'po_box'.\n",
    "    \"\"\"\n",
    "    # Elimina nulos\n",
    "    v_nomdf = v_nomdf.dropna(subset=[v_nomcol])\n",
    "\n",
    "    # Filtra las cadenas de más de 8 caracteres\n",
    "    v_nomdf = v_nomdf[v_nomdf[v_nomcol].str.len() == 8]\n",
    "\n",
    "    # Filtra los registros con formato incorrecto\n",
    "    v_nomdf = v_nomdf[v_nomdf[v_nomcol].str.contains(r\"^[A-Z]{2}\\s\\d{5}$\", na=False)]\n",
    "\n",
    "    # Reindexa los datos\n",
    "    v_nomdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Función que separa el campo 'state_po_box'\n",
    "    def split_state_po_box(s):\n",
    "        parts  = s.split(' ')\n",
    "        state  = parts[0]\n",
    "        po_box = parts[1]\n",
    "        return state, po_box\n",
    "\n",
    "    # Aplica la función y crea las cols nuevas\n",
    "    state_po_box_split = v_nomdf[v_nomcol].apply(split_state_po_box)\n",
    "    v_nomdf[['state', 'po_box']] = pd.DataFrame(state_po_box_split.tolist(), columns=['state', 'po_box'])\n",
    "\n",
    "    # Elimina las columnas temporales\n",
    "    v_nomdf.drop(columns=['state_po_box', 'nom_biz', 'address'], inplace=True)\n",
    "    \n",
    "    # Renombra la columna 'street', como 'address' \n",
    "    v_nomdf.rename(columns={'street': 'address'}, inplace=True)\n",
    "\n",
    "    return v_nomdf\n",
    "\n",
    "# Ejemplo de uso\n",
    "df_gAddress = f_separaState(df_gAddress, 'state_po_box')\n",
    "print(df_gAddress.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Función: Convierte datos de categorías a un diccionario<a class=\"anchor\" id=\"23\"></a>\n",
    "\n",
    "    Para facilitar la manipulación de las categorías, se convierten a un diccionario\n",
    "\n",
    "Args:\n",
    "\n",
    "data = Un set de datos copiados de internet \n",
    "\n",
    "Retorna: \n",
    "\n",
    "Un diccionario\n",
    "\n",
    "Nota: \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_convertData2Dic(data):\n",
    "    dic_gcatg = {}\n",
    "    current_letter = ''\n",
    "    \n",
    "    for line in data.split('\\n'):\n",
    "        if line.startswith(\"Letra\"):\n",
    "            current_letter = line.split(\" \")[-1]\n",
    "            dic_gcatg[current_letter] = []\n",
    "        elif line.strip() != '':\n",
    "            dic_gcatg[current_letter].append(line.strip())\n",
    "    total_elements = sum(len(categories) for categories in dic_gcatg.values())\n",
    "    \n",
    "    return dic_gcatg, total_elements\n",
    "\n",
    "data = \"\"\"\n",
    "Letra A\n",
    "Abogado\n",
    "Acupunturista\n",
    "Agencia de adopción\n",
    "Agencia de empleo\n",
    "Agencia de marketing digital\n",
    "Agencia de viajes\n",
    "Agencia inmobiliaria\n",
    "Agente de seguros\n",
    "Almacenamiento\n",
    "Alquiler de coches\n",
    "Armería\n",
    "Asesor financiero\n",
    "Asesoría fiscal\n",
    "Asesoría jurídica\n",
    "Asesoría de negocios\n",
    "Asesoría de recursos humanos\n",
    "Asistencia sanitaria a domicilio\n",
    "Asociación\n",
    "Atención al cliente\n",
    "Autoescuela\n",
    "Letra B\n",
    "Barbería\n",
    "Barco turístico\n",
    "Belleza y cosmética\n",
    "Biblioteca\n",
    "Bicicletas\n",
    "Bienes raíces\n",
    "Letra C\n",
    "Cafetería\n",
    "Caja de ahorros\n",
    "Carpintería\n",
    "Centro comercial\n",
    "Centro de conferencias\n",
    "Centro de congresos\n",
    "Centro de convenciones\n",
    "Centro de estética\n",
    "Centro de eventos\n",
    "Centro de fisioterapia\n",
    "Centro de jardinería\n",
    "Centro de masajes\n",
    "Centro de negocios\n",
    "Centro de osteopatía\n",
    "Centro de quiromasaje\n",
    "Centro de rehabilitación\n",
    "Centro de salud\n",
    "Centro de yoga\n",
    "Centro deportivo\n",
    "Centro educativo\n",
    "Centro veterinario\n",
    "Cervecería\n",
    "Club deportivo\n",
    "Cocina italiana\n",
    "Cocina mexicana\n",
    "Cocina peruana\n",
    "Cocina vegetariana\n",
    "Comida para llevar\n",
    "Comida rápida\n",
    "Compañía de seguros\n",
    "Concesionario de coches\n",
    "Consignación y venta de ropa\n",
    "Consultoría\n",
    "Contable\n",
    "Cooperativa\n",
    "Corte y confección\n",
    "Crepería\n",
    "Cuidado de animales\n",
    "Cuidado de niños\n",
    "Cuidado de personas mayores\n",
    "Letra D\n",
    "Decoración del hogar\n",
    "Dentista\n",
    "Deportes extremos\n",
    "Desguace de coches\n",
    "Despacho de abogados\n",
    "Despacho de arquitectos\n",
    "Despacho de ingenieros\n",
    "Discoteca\n",
    "Distribuidor de alimentos\n",
    "Distribuidor de productos de belleza\n",
    "Letra E\n",
    "Electricista\n",
    "Empresa de construcción\n",
    "Empresa de limpieza\n",
    "Empresa de mudanzas\n",
    "Empresa de seguridad\n",
    "Enseñanza de idiomas\n",
    "Equipo deportivo\n",
    "Establecimiento de comida\n",
    "Estación de servicio\n",
    "Estética\n",
    "Estudio de grabación\n",
    "Estudio de tatuajes\n",
    "Letra F\n",
    "Fabricante de muebles\n",
    "Ferretería\n",
    "Floristería\n",
    "Fotógrafo\n",
    "Funeraria\n",
    "Letra G\n",
    "Galería de arte\n",
    "Gimnasio\n",
    "Letra H\n",
    "Heladería\n",
    "Hospital\n",
    "Hostal\n",
    "Hotel\n",
    "Letra I\n",
    "Inmobiliaria\n",
    "Instituto de belleza\n",
    "Letra J\n",
    "Joyería\n",
    "Letra K\n",
    "Kiosco\n",
    "Letra L\n",
    "Lavandería\n",
    "Librería\n",
    "Licorería\n",
    "Limpieza\n",
    "Limpieza de alfombras\n",
    "Limpieza de piscinas\n",
    "Limpieza de ventanas\n",
    "Logopeda\n",
    "Letra M\n",
    "Maquinaria pesada\n",
    "Masajista\n",
    "Matrimonio\n",
    "Mensajería\n",
    "Mercería\n",
    "Mueblería\n",
    "Letra N\n",
    "Nacimiento\n",
    "Necesidades educativas especiales\n",
    "Necesidades especiales\n",
    "Negocios y economía\n",
    "Neonatología\n",
    "Nieve\n",
    "Nueva era\n",
    "Nudismo\n",
    "Nutrición\n",
    "Letra O\n",
    "Obesidad\n",
    "Objetos perdidos y encontrados\n",
    "Obstetricia y ginecología\n",
    "Ocio y entretenimiento\n",
    "Oficina de correos\n",
    "Oficina de empleo\n",
    "Oficina de inmigración\n",
    "Oficina de turismo\n",
    "Oficina del abogado\n",
    "Oficina del gobierno\n",
    "Oficina del registro civil\n",
    "Oficinas corporativas\n",
    "Oficinas de correos y servicios de envío\n",
    "Oficinas de empleo y agencias de reclutamiento\n",
    "Oficinas de impuestos\n",
    "Oficinas de servicios sociales\n",
    "Oftalmología\n",
    "Ópticas\n",
    "Ortopedia y traumatología\n",
    "Ortopedias\n",
    "Orquesta\n",
    "Osteopatía\n",
    "Otorrinolaringología\n",
    "Otras mascotas\n",
    "Otros deportes\n",
    "Otros servicios\n",
    "Otros servicios de construcción\n",
    "Otros servicios de salud y bienestar\n",
    "Otros servicios de reparación de automóviles\n",
    "Otros servicios profesionales\n",
    "Letra P\n",
    "Paddleboarding\n",
    "Paintball\n",
    "Paleontología\n",
    "Panaderías\n",
    "Panteones\n",
    "Papelerías\n",
    "Paracaidismo\n",
    "Parapente\n",
    "Parasitología\n",
    "Parques\n",
    "Parques acuáticos\n",
    "Parques de atracciones\n",
    "Parques de diversiones\n",
    "Parques nacionales\n",
    "Partes y suministros para electrodomésticos\n",
    "Partes y suministros para herramientas eléctricas\n",
    "Partes y suministros para motocicletas\n",
    "Partes y suministros para vehículos\n",
    "Patinaje sobre hielo\n",
    "Patinaje sobre ruedas\n",
    "Patines y patinetas\n",
    "Pavimentación y asfalto\n",
    "Pediatría\n",
    "Películas\n",
    "Peluquerías\n",
    "Pensión para mascotas\n",
    "Perforación de pozos\n",
    "Perros\n",
    "Personal de limpieza\n",
    "Personal de mudanzas\n",
    "Personal de reparación y remodelación del hogar\n",
    "Personal de seguridad\n",
    "Pesca\n",
    "Pescaderías\n",
    "Pestañas\n",
    "Petróleo y gas\n",
    "Piezas de automóviles usadas\n",
    "Pintores\n",
    "Pintura corporal\n",
    "Pinturas y decoración del hogar\n",
    "Piscinas\n",
    "Pisos de madera\n",
    "Pisos laminados\n",
    "Pisos y alfombras\n",
    "Pizzerías\n",
    "Planificación financiera\n",
    "Planificación funeraria y servicios conmemorativos\n",
    "Plantas y flores\n",
    "Plomería\n",
    "Plomeros\n",
    "Podólogos\n",
    "Políticos\n",
    "Pollo frito\n",
    "Poner una inyección\n",
    "Ponerse en forma\n",
    "Porches y patios\n",
    "Portones eléctricos\n",
    "Posicionamiento web y marketing en línea\n",
    "Postproducción de películas\n",
    "Potros y caballos\n",
    "Prensa y publicaciones\n",
    "Prestamistas\n",
    "Prevención de plagas\n",
    "Prevención y tratamiento de lesiones\n",
    "Préstamos\n",
    "Productos agrícolas\n",
    "Productos de belleza\n",
    "Productos de panadería y repostería\n",
    "Productos de piscina y spa\n",
    "Productos de tabaco\n",
    "Productos del mar\n",
    "Productos farmacéuticos\n",
    "Productos lácteos\n",
    "Productos orgánicos\n",
    "Productos para el hogar\n",
    "Productos para mascotas\n",
    "Productos para piscinas\n",
    "Productos para piscinas y spas\n",
    "Productos para piscinas y suministros\n",
    "Productos para piscinas, suministros y servicios\n",
    "Productos para piscinas, suministros y servicios para piscinas\n",
    "Productos para protección de la piel\n",
    "Profesionales de la salud\n",
    "Propano\n",
    "Propiedades comerciales y de inversión\n",
    "Propiedades residenciales\n",
    "Protección contra el sol\n",
    "Psicólogos\n",
    "Psiquiatría\n",
    "Publicidad\n",
    "Pubs\n",
    "Pulgas y garrapatas\n",
    "Purificadores de aire y agua\n",
    "Letra R\n",
    "Radiología\n",
    "Ranchos\n",
    "Rastreador de actividad física\n",
    "Rastreador de fitness\n",
    "Rastreador de salud\n",
    "Rastreador de sueño\n",
    "Rastreador de temperatura corporal\n",
    "Realizador de vídeo\n",
    "Reciclaje\n",
    "Recinto ferial\n",
    "Reforma de baños\n",
    "Reforma de cocinas\n",
    "Reforma de hogares\n",
    "Reforma de interiores\n",
    "Reforma de oficinas\n",
    "Reforma de viviendas\n",
    "Regalos\n",
    "Regalos corporativos\n",
    "Registro civil\n",
    "Rehabilitación\n",
    "Rehabilitación de edificios\n",
    "Relaciones públicas\n",
    "Relojería\n",
    "Reparación de bicicletas\n",
    "Reparación de electrodomésticos\n",
    "Reparación de móviles\n",
    "Reparación de ordenadores\n",
    "Reparación de zapatos\n",
    "Repostería\n",
    "Residencia de ancianos\n",
    "Restauración\n",
    "Restaurante\n",
    "Resumen financiero\n",
    "Ropa\n",
    "Rotulación\n",
    "Rugby\n",
    "Letra S\n",
    "Sala de cine\n",
    "Salón de belleza\n",
    "Salón de eventos\n",
    "Salón de té\n",
    "Salud y bienestar\n",
    "Sastrería\n",
    "Segunda mano\n",
    "Seguridad\n",
    "Seguros\n",
    "Servicio de catering\n",
    "Servicio de conserjería\n",
    "Servicio de corte de árboles\n",
    "Servicio de entregas\n",
    "Servicio de lavandería\n",
    "Servicio de limpieza\n",
    "Servicio de mensajería\n",
    "Servicio de mudanzas\n",
    "Servicio de pintura\n",
    "Servicio de reparación de automóviles\n",
    "Servicio de reparación de cristales\n",
    "Servicio de reparación de teléfonos móviles\n",
    "Servicio de transporte\n",
    "Servicio de traducción\n",
    "Servicio técnico\n",
    "Servicios de diseño gráfico\n",
    "Servicios de marketing\n",
    "Servicios funerarios\n",
    "Sex shop\n",
    "Showroom\n",
    "Skate\n",
    "Spa\n",
    "Suministros de oficina\n",
    "Supermercado\n",
    "Surf\n",
    "Letra T\n",
    "Taller mecánico\n",
    "Taller de chapa y pintura\n",
    "Tatuajes y piercings\n",
    "Taxi\n",
    "Teatro\n",
    "Telecomunicaciones\n",
    "Terapeuta ocupacional\n",
    "Terapia\n",
    "Tienda de animales\n",
    "Tienda de bicicletas\n",
    "Tienda de comestibles\n",
    "Tienda de cosméticos\n",
    "Tienda de deportes\n",
    "Tienda de electrónica\n",
    "Tienda de equipos de oficina\n",
    "Tienda de flores\n",
    "Tienda de instrumentos musicales\n",
    "Tienda de libros\n",
    "Tienda de muebles\n",
    "Tienda de ropa\n",
    "Tienda de ropa para bebés\n",
    "Tienda de zapatos\n",
    "Tintorería\n",
    "Tiro con arco\n",
    "Tirolesa\n",
    "Topografía\n",
    "Torrefacción de café\n",
    "Tostador de café\n",
    "Tour operador\n",
    "Trabajos de acabado\n",
    "Trabajos de construcción\n",
    "Trabajos de jardinería\n",
    "Trabajos de limpieza\n",
    "Trabajos de pintura\n",
    "Trabajos de plomería\n",
    "Trabajos eléctricos\n",
    "Trabajos en acero\n",
    "Tragamonedas\n",
    "Transporte de motocicletas\n",
    "Transporte de vehículos\n",
    "Transporte marítimo\n",
    "Tratamiento de aguas\n",
    "Tratamiento de basuras\n",
    "Letra U\n",
    "Universidad\n",
    "Urólogo\n",
    "Letra V\n",
    "Vehículo eléctrico\n",
    "Vehículo todo terreno\n",
    "Veterinario\n",
    "Viñedo\n",
    "Vivero\n",
    "Letra W\n",
    "Web Designer\n",
    "Wedding planner\n",
    "Letra Z\n",
    "Zapatería\n",
    "Zoo\n",
    "\"\"\"\n",
    "\n",
    "dic_gcatg, total_elements = f_convertData2Dic(data)\n",
    "print (f'El total de categorías es : {total_elements}')\n",
    "for letter, categories in dic_gcatg.items():\n",
    "    print(f\"Letra {letter}:\")\n",
    "    print(categories)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Función: Agrega Estado<a class=\"anchor\" id=\"24\"></a>\n",
    "\n",
    "    Agrega el estado como par clave:valor\n",
    "\n",
    "Args:\n",
    "\n",
    "Nada\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Inserta el campo 'state' y su clave\n",
    "\n",
    "Nota: Se debe modificar para que sea paramétrica y responda a los argumentos o una lista de argumentos\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función: Agrega campo en BBDD Mongo \n",
    "# ***********************************\n",
    "# Establece una conexión con Mongo DB, genera \n",
    "# una consulta e inserta un nuevo par clave:valor\n",
    "# \n",
    "# Parámetros\n",
    "# Recibe  : Nada\n",
    "# Retorna : Inserta datos en toda la BBDD\n",
    "# Nota: Para esta versión, se parametriza en la conexión\n",
    "#\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def f_addState():\n",
    "    # Establece conexión con MongoDB\n",
    "    client     = MongoClient('localhost', 27017)\n",
    "    db         = client['googledb']\n",
    "    collection = db['grevFlorida']\n",
    "    \n",
    "    # Agrega la clave:valor \"state\":\"AL\" a todos los registros\n",
    "    collection.update_many({}, {'$set': {'state': 'FL'}})\n",
    "    \n",
    "    # Cerrar la conexión\n",
    "    client.close()\n",
    "\n",
    "# Llamar al procedimiento para agregar la clave \"state\" a todos los registros\n",
    "f_addState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. Función: Elimina datos de colección Mongo DB<a class=\"anchor\" id=\"25\"></a>\n",
    "\n",
    "    Borra los datos de una colección\n",
    "\n",
    "Args:\n",
    "\n",
    "Nada\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Borra los datos de la BBDD\n",
    "\n",
    "Nota: Se debe modificar para que sea paramétrica y responda a los argumentos o una lista de argumentos\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "def f_eliminaDatosMongo():\n",
    "    \"\"\"\n",
    "    Elimina datos creados en BBDD Mongo\n",
    "    Se parametriza en la conexión\n",
    "    \"\"\"\n",
    "    \n",
    "    # Establece conexión con la base de datos de MongoDB\n",
    "    client     = MongoClient('localhost', 27017)\n",
    "    db         = client['googlef']\n",
    "    collection = db['setf']\n",
    "    \n",
    "    # Columnas o pares clave:valor a eliminar\n",
    "    v_remueveCols = [\n",
    "        'name', 'address', 'description', 'latitude', 'longitude',\n",
    "        'avg_rating', 'num_of_reviews', 'price', 'state',\n",
    "        'relative_results', 'url'\n",
    "    ]\n",
    "    \n",
    "    # Itera sobre la colección y elimina las clave:valor de la lista\n",
    "    for v_docs in collection.find():\n",
    "        for v_col in v_remueveCols:\n",
    "            if v_col in v_docs:\n",
    "                del v_docs[v_col]\n",
    "        # Actualiza en la colección sin las clave:valor eliminadas (reindex)\n",
    "        collection.replace_one({'_id': v_docs['_id']}, v_docs)\n",
    "    \n",
    "    # Cierra la conexión\n",
    "    client.close()\n",
    "\n",
    "# Llamar al procedimiento para eliminar las columnas/pares clave:valor de la colección\n",
    "f_eliminaDatosMongo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. Función: Analiza faltantes<a class=\"anchor\" id=\"26\"></a>\n",
    "\n",
    "   Analiza faltantes en un df\n",
    "Args:\n",
    "\n",
    "v_nomdf = dataframe\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Inserta el campo 'state' y su clave\n",
    "\n",
    "Nota: Se debe modificar para que sea paramétrica y responda a los argumentos o una lista de argumentos\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El df tiene 3 columnas.\n",
      "Hay 2 columnas que tienen valores faltantes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores faltantes</th>\n",
       "      <th>% de Valores Totales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>87823</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Valores faltantes  % de Valores Totales\n",
       "address              87823                   2.7\n",
       "name                    37                   0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_datosFaltantes(v_nomdf):\n",
    "        # Total valores faltantes\n",
    "        mis_val = v_nomdf.isnull().sum()\n",
    "\n",
    "        # Pocentaje de faltantes\n",
    "        mis_val_percent = 100 * v_nomdf.isnull().sum() / len(v_nomdf)\n",
    "\n",
    "        # Tabla resultados\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "        # Nombra columnas\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Valores faltantes', 1 : '% de Valores Totales'})\n",
    "\n",
    "        # Ordena la tabla por porcentaje de datos faltantes\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% de Valores Totales', ascending=False).round(1)\n",
    "\n",
    "        # Resumen de la info\n",
    "        print(((f\"El df tiene {str(v_nomdf.shape[1])}\" +\n",
    "                \" columnas.\\n\"\n",
    "                \"Hay \") + str(mis_val_table_ren_columns.shape[0]) +\n",
    "               \" columnas que tienen valores faltantes.\"))\n",
    "\n",
    "        return mis_val_table_ren_columns\n",
    "    \n",
    "# Testing\n",
    "# *******\n",
    "#\n",
    "v_nomdf = df_gAddress\n",
    "f_datosFaltantes(v_nomdf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27. Función: Rango de fechas<a class=\"anchor\" id=\"27\"></a>\n",
    "\n",
    "   Calcula el rango de fechas de un set de datos en GOOGLE\n",
    "\n",
    "Args:\n",
    "\n",
    "mongo_host      = 'localhost'\n",
    "\n",
    "mongo_port      = 27017\n",
    "\n",
    "db_name         = 'googledb'\n",
    "\n",
    "collection_name = 'grevCalifornia'\n",
    "\n",
    "campo           = 'time'\n",
    "\n",
    "Retorna: \n",
    "\n",
    "Un mensaje con el rango de fechas\n",
    "\n",
    "Nota: Revisar, se hizo rápido y retorna valores del año 90, cuando no había internet\n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El set de datos se extiende desde la fecha 1990-12-30 21:00:00, hasta el 2021-09-08 22:00:32.337000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Parámetros de conexión a la base de datos MongoDB\n",
    "mongo_host      = 'localhost'\n",
    "mongo_port      = 27017\n",
    "db_name         = 'googledb'\n",
    "collection_name = 'grevCalifornia'\n",
    "campo           = 'time'\n",
    "\n",
    "# Función para convertir valores de 'time' a fechas\n",
    "def f_convierteFecms(v_claveval):\n",
    "    if isinstance(v_claveval, (int, float)):\n",
    "        v_valfec = int(v_claveval)\n",
    "        \n",
    "        if v_valfec > 9999999999:\n",
    "            v_valfec /= 1000\n",
    "        \n",
    "        return datetime.datetime.fromtimestamp(v_valfec)\n",
    "    elif isinstance(v_claveval, str):\n",
    "        v_valfec = int(v_claveval[:-2])  # Eliminar los dos últimos caracteres \".0\"\n",
    "        \n",
    "        if v_valfec > 9999999999:\n",
    "            v_valfec /= 1000\n",
    "        \n",
    "        return datetime.datetime.fromtimestamp(v_valfec)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Conexión a la base de datos de MongoDB\n",
    "client     = MongoClient(mongo_host, mongo_port)\n",
    "db         = client[db_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Construir la consulta\n",
    "query = {\n",
    "    campo: {'$exists': True}\n",
    "}\n",
    "\n",
    "# Ejecutar la consulta y procesar los resultados\n",
    "cursor = collection.find(query)\n",
    "result_dataframe = []\n",
    "\n",
    "for doc in cursor:\n",
    "    fecha_converted = f_convierteFecms(doc[campo])\n",
    "    if fecha_converted is not None:\n",
    "        doc['fecha'] = fecha_converted\n",
    "        result_dataframe.append(doc)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "client.close()\n",
    "\n",
    "# Crear DataFrame a partir de los resultados procesados\n",
    "df_grev = pd.DataFrame(result_dataframe)\n",
    "\n",
    "# Calcular rango de fechas\n",
    "fecha_menor = df_grev['fecha'].min()\n",
    "fecha_mayor = df_grev['fecha'].max()\n",
    "\n",
    "# Imprimir el rango de fechas\n",
    "print(f'El set de datos se extiende desde la fecha {fecha_menor}, hasta el {fecha_mayor}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28. Función: Crea BBDD \"diccionario\" en SQLite<a class=\"anchor\" id=\"28\"></a>\n",
    "\n",
    "    Lorem ipsum\n",
    "\n",
    "Args:\n",
    "\n",
    "\n",
    "Retorna: \n",
    "\n",
    "\n",
    "Nota: \n",
    "\n",
    "[Volver - Tabla de Contenidos](#0-0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
